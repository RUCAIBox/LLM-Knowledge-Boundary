# LLM-Knowledge-Boundary

## üöÄ Quick Start

1. Preprocess data and install dependencies.
    ```bash
    bash preparation.sh
    python data_preparation.py -d [nq/tq/hq]
    ```

2. Get supporting documents generated by ChatGPT (take Natural Questions dataset as an example).
    ```bash
    OPENAI_API_KEY=[your api key] \
    python run_llm.py \
        --source=data/source/nq.json \
        --usechat \
        --type=generate \
        --ra=none \
        --outfile=data/source/nq-chat.json
    ```

## üîç Key Findings

1. Question answering.
    ```bash
    OPENAI_API_KEY=[your api key] \
    python run_llm.py \
        --source=data/source/nq-chat.json \
        --usechat \
        --type=qa \
        --ra=none \
        --outfile=data/qa/nq-none-qa.json
    ```
2. Priori judging.
    ```bash
    OPENAI_API_KEY=[your api key] \
    python run_llm.py \
        --source=data/source/nq-chat.json \
        --type=prior \
        --ra=dense \
        --outfile=data/prior/nq-dense-prior.json
    ```
3. Posteriori judging.
    ```bash
    OPENAI_API_KEY=[your api key] \
    python run_llm.py \
        --source=data/qa/nq-none-qa.json \
        --usechat \
        --type=post \
        --ra=sparse \
        --outfile=data/post/nq-sparse-post.json
    ```